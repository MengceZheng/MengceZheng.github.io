name: Get Citation Data

on:
  page_build:
  schedule:
    - cron: '0 8 * * *'  # 可根据需求调整频率

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.x'

    - name: Cache dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-python-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-python-

    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install -r ./google_scholar_crawler/requirements.txt

    - name: Run crawler
      run: |
        cd ./google_scholar_crawler
        python main.py
      env: 
        GOOGLE_SCHOLAR_ID: ${{ secrets.GOOGLE_SCHOLAR_ID }}

    - name: Push results to repository
      run: |
        cd ./google_scholar_crawler/results
        git init
        git config --local user.name "${GITHUB_ACTOR}"
        export remote_repo="https://${GITHUB_ACTOR}:${{ secrets.GITHUB_TOKEN }}@github.com/${GITHUB_REPOSITORY}.git"
        git add *.json
        git commit -m "Updated Citation Data"
        git push "${remote_repo}" HEAD:google-scholar-stats --force
      env: 
        GOOGLE_SCHOLAR_ID: ${{ secrets.GOOGLE_SCHOLAR_ID }}
